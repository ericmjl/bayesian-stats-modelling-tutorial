{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is probability? A simulated introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Objectives of Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To have an understanding of what \"probability\" means, in both Bayesian and Frequentist terms;\n",
    "- To be able to simulate probability distributions that model real-world phenomena;\n",
    "- To understand and be able to simulate joint probabilities and conditional probabilities;\n",
    "- To understand Bayes' Theorem and its utility."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> To the pioneers such as Bernoulli, Bayes and Laplace, a probability represented a _degree-of-belief_ or plausibility; how much they thought that something was true, based on the evidence at hand. To the 19th century scholars, however, this seemed too vague and subjective an idea to be the basis of a rigorous mathematical theory. So they redefined probability as the _long-run relative frequency_ with which an event occurred, given (infinitely) many repeated (experimental) trials. Since frequencies can be measured, probability was now seen as an objective tool for dealing with _random_ phenomena.\n",
    "\n",
    "-- _Data Analysis, A Bayesian Tutorial_, Sivia & Skilling (p. 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What type of random phenomena are we talking about here? One example is:\n",
    "\n",
    "- Knowing that a website has a click-through rate (CTR) of 10%, we can calculate the probabilty of having 10 people, 9 people, 8 people ... and so on click through, upon drawing 10 people randomly from the population;\n",
    "- But given the data of how many people click through, how can we calculate the CTR? And how certain can we be of this CTR? Or how likely is a particular CTR?\n",
    "\n",
    "Science mostly asks questions of the second form above & Bayesian thinking provides a wondereful framework for answering such questions. Essentially Bayes' Theorem gives us a way of moving from the probability of the data given the model (written as $P(data|model)$) to the probability of the model given the data ($P(model|data)$).\n",
    "\n",
    "We'll first explore questions of the 1st type using simulation: knowing the model, what is the probability of seeing certain data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Simulating probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Let's say that a website has a CTR of 50%, i.e. that 50% of people click through. If we picked 1000 people at random from thepopulation, how likely would it be to find that a certain number of people click?\n",
    "\n",
    "We can simulate this using `numpy`'s random number generator.\n",
    "\n",
    "To do so, first note we can use `np.random.rand()` to randomly select floats between 0 and 1 (known as the _uniform distribution_). Below, we do so and plot a histogram:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw 1,000 samples from uniform & plot results\n",
    "x = np.random.rand(1000)\n",
    "plt.hist(x);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To then simulate the sampling from the population, we check whether each float was greater or less than 0.5. If less than or equal to 0.5, we say the person clicked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computed how many people click\n",
    "clicks = x <= 0.5\n",
    "n_clicks = sum(clicks)\n",
    "f\"Number of clicks = {n_clicks}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The proportion of people who clicked can be calculated as the total number of clicks over the number of people:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computed proportion of people who clicked\n",
    "f\"Proportion who clicked = {n_clicks/len(clicks)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discussion**: Did you get the same answer as your neighbour? If you did, why? If not, why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Up for discussion:** Let's say that all you had was this data and you wanted to figure out the CTR (probability of clicking). \n",
    "\n",
    "* What would your estimate be?\n",
    "* Bonus points: how confident would you be of your estimate?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** Although, in the above, we have described _probability_ in two ways, we have not described it mathematically. We're not going to do so rigorously here, but we will say that _probabilty_ defines a function from the space of possibilities (in the above, the interval $[0,1]$) that describes how likely it is to get a particular point or region in that space. Mike Betancourt has an elegant [Introduction to Probability Theory (For Scientists and Engineers)](https://betanalpha.github.io/assets/case_studies/probability_theory.html) that I can recommend."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hands-on: more clicking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use random sampling to simulate how many people click when the CTR is 0.7. How many click? What proportion?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution\n",
    "clicks = x <= 0.7\n",
    "n_clicks = sum(clicks)\n",
    "print(f\"Number of clicks = {n_clicks}\")\n",
    "print(f\"Proportion who clicked = {n_clicks/len(clicks)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Discussion point_: This model is know as the bias coin flip. \n",
    "- Can you see why?\n",
    "- Can it be used to model other phenomena?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Galapagos finch beaks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also calculate such proportions with real-world data. Here we import a dataset of Finch beak measurements from the GalÃ¡pagos islands. You can find the data [here](https://datadryad.org/resource/doi:10.5061/dryad.9gh90)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import and view head of data\n",
    "df_12 = pd.read_csv('../data/finch_beaks_2012.csv')\n",
    "df_12.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store lengths in a pandas series\n",
    "lengths = df_12['blength']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* What proportion of birds have a beak length > 10 ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = (sum(lengths > 10))/len(lengths)\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** This is the proportion of birds that have beak length $>10$ in your empirical data, not the probability that any bird drawn from the population will have beak length $>10$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A proxy for probability\n",
    "\n",
    "As stated above, we have calculated a proportion, not a probability. As a proxy for the probability, we can simulate drawing random samples (with replacement) from the data seeing how many lengths are > 10 and calculating the proportion (commonly referred to as [hacker statistics](https://speakerdeck.com/jakevdp/statistics-for-hackers)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 10000\n",
    "sum(np.random.choice(lengths, n_samples, replace=True) > 10)/n_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another way to simulate coin-flips"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above, you have used the uniform distribution to sample from a series of biased coin flips. I want to introduce you to another distribution that you can also use to do so: the **binomial distribution**.\n",
    "\n",
    "The **binomial distribution** with parameters $n$ and $p$ is defined as the probability distribution of\n",
    "\n",
    "> the number of heads seen when flipping a coin $n$ times when  with $p(heads)=p$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note** that this distribution essentially tells the _story_ of a general model in the following sense: if we believe that they underlying process generating the observed data has a binary outcome (affected by disease or not, head or not, 0 or 1, clicked through or not), and that one the of the two outcomes occurs with probability $p$, then the probability of seeing a particular outcome is given by the **binomial distribution** with parameters $n$ and $p$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll now use the binomial distribution to answer the same question as above:\n",
    "* If P(heads) = 0.7 and you flip the coin ten times, how many heads will come up?\n",
    "\n",
    "We'll also set the seed to ensure reproducible results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed\n",
    "np.random.seed(seed=16071982)\n",
    "\n",
    "# Simulate one run of flipping the biased coin 10 times\n",
    "np.random.binomial(10, 0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulating many times to get the distribution\n",
    "\n",
    "In the above, we have simulated the scenario once. But this only tells us one potential outcome. To see how likely it is to get $n$ heads, for example, we need to simulate it a lot of times and check what proportion ended up with $n$ heads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate 1,000 run of flipping the biased coin 10 times\n",
    "x = np.random.binomial(10, 0.3, 10000)\n",
    "\n",
    "# Plot normalized histogram of results\n",
    "plt.hist(x, density=True, bins=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Group chat: what do you see in the above?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hands-on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- If I flip a biased coin ($P(H)=0.3$) 20 times, what is the probability of 5 or more heads?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution\n",
    "sum(np.random.binomial(20, 0.3, 10000) >= 5)/10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- If I flip a fair coin 20 times, what is the probability of 5 or more heads?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(np.random.binomial(20,0.5,10000) >= 5)/10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Plot the normalized histogram of number of heads of the following experiment: flipping a fair coin 10 times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histogram \n",
    "x = np.random.binomial(10, 0.5, 10000)\n",
    "plt.hist(x, density=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** you may have noticed that the _binomial distribution_ can take on only  a finite number of values, whereas the _uniform distribution_ above can take on any number between $0$ and $1$. These are different enough cases to warrant special mention of this & two different names: the former is called a _probability mass function_ (PMF) and the latter a _probability distribution function_ (PDF). Time permitting, we may discuss some of the subtleties here. If not, all good texts will cover this. I like (Sivia & Skilling, 2006), among many others.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Joint Probability & Conditional Probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joint Probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have already encountered joint probabilities above, perhaps without knowing it: $P(A,B)$ is the probability two events $A$ and $B$ _both_ occurring.\n",
    "* For example, getting two heads in a row.\n",
    "\n",
    "If $A$ and $B$ are independent, then $P(A,B)=P(A)P(B)$ but be warned: this is not always (or often) the case.\n",
    "\n",
    "One way to think of this is considering \"AND\" as multiplication: the probability of A **and** B is the probability of A **multiplied** by the probability of B."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HANDS-ON: JOINT PROBABILITY COIN FLIPPING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify that $P(A,B)=P(A)P(B)$ in the two fair coin-flip case (A=heads, B=heads) by \n",
    "- first simulating two coins being flipped together and calculating the proportion of occurences with two heads;\n",
    "- then simulating one coin flip and calculating the proportion of heads and then doing that again and multiplying the two proportions.\n",
    "\n",
    "Your two calculations should give \"pretty close\" results and not the same results due to the (in)accuracy of simulation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution: Calculate P(A,B)\n",
    "x_0 = np.random.binomial(2, 0.5, 10000)\n",
    "p_ab = sum(x_0==2)/len(x_0)\n",
    "plt.hist(x_0);\n",
    "print(p_ab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution: Calculate P(A)P(B)\n",
    "x_1 = np.random.binomial(1, 0.5, 10000)\n",
    "x_2 = np.random.binomial(1, 0.5, 10000)\n",
    "p_a = sum(x_1 == 1)/len(x_1)\n",
    "p_b = sum(x_2 == 1)/len(x_2)\n",
    "p_a*p_b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** In order to use such simulation and _hacker statistics_ approaches to \"prove\" results such as the above, we're gliding over several coupled and deep technicalities. This is in the interests of the pedagogical nature of this introduction. For the sake of completeness, we'll mention that we're essentially\n",
    "- Using the proportion in our simulations as a proxy for the probability (which, although Frequentist, is useful to allow you to start getting your hands dirty with probability via simluation).\n",
    "\n",
    "Having stated this, for ease of instruction, we'll continue to do so when thinking about joint & conditional probabilities of both simulated and real data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HANDS-ON: joint probability for birds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the probability that two randomly selected birds have beak depths over 10 ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate P(A)P(B) of two birds having beak lengths > 10\n",
    "p_a = (sum(lengths > 10))/len(lengths)\n",
    "p_b = (sum(lengths > 10))/len(lengths)\n",
    "p_a*p_b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Calculate the joint probability using the resampling method, that is, by drawing random samples (with replacement) from the data. First calculate $P(A)P(B)$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate P(A)P(B) using resampling methods\n",
    "n_samples = 100000\n",
    "p_a = sum(np.random.choice(lengths, n_samples, replace=True) > 10)/n_samples\n",
    "p_b = sum(np.random.choice(lengths, n_samples, replace=True) > 10)/n_samples\n",
    "p_a*p_b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now calculate $P(A,B)$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate P(A,B) using resampling methods\n",
    "n_samples = 100000\n",
    "samples = np.random.choice(lengths, (n_samples,2), replace=True)\n",
    "_ = samples > (10, 10)\n",
    "p_ab = sum(np.prod(_, axis=1))/n_samples\n",
    "p_ab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task:** Interpret the results of your simulations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conditional Probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a grasp on joint probabilities, lets consider conditional probabilities, that is, the probability of some $A$, knowing that some other $B$ is true. We use the notation $P(A|B)$ to denote this. For example, you can ask the question \"What is the probability of a finch beak having depth $<10$, knowing that the finch of of species 'fortis'?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example: conditional probability for birds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. What is the probability of a finch beak having depth > 10 ?\n",
    "2. What if we know the finch is of species 'fortis'?\n",
    "3. What if we know the finch is of species 'scandens'?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(df_12.blength > 10)/len(df_12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fortis = df_12.loc[df_12['species'] == 'fortis']\n",
    "sum(df_fortis.blength > 10)/len(df_fortis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scandens = df_12.loc[df_12['species'] == 'scandens']\n",
    "sum(df_scandens.blength > 10)/len(df_scandens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** These proportions are definitely different. We can't say much more currently but we'll soon see how to use hypothesis testing to see what else we can say about the differences between the species of finches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joint and conditional probabilities\n",
    "\n",
    "Conditional and joint probabilites are related by the following:\n",
    "$$ P(A,B) = P(A|B)P(B)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Homework exercise for the avid learner:** verify the above relationship using simulation/resampling techniques in one of the cases above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hands on example: drug testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Suppose that a test for using a particular drug is 99% sensitive and 99% specific. That is, the test will produce 99% true positive results for drug users and 99% true negative results for non-drug users. Suppose that 0.5% (5 in 1,000) of people are users of the drug. What is the probability that a randomly selected individual with a positive test is a drug user?\n",
    "\n",
    "**If we can answer this, it will be really cool as it shows how we can move from knowing $P(+|user)$ to $P(user|+)$, a MVP for being able to move from $P(data|model)$ to $P(model|data)$.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the spirit of this workshop, it's now time to harness your computational power and the intuition of simulation to solve this drug testing example. \n",
    "\n",
    "* Before doing so, what do you think the answer to the question _\"What is the probability that a randomly selected individual with a positive test is a drug user?\"_ is? Write down your guess."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take 10,000 subjects\n",
    "n = 100000\n",
    "# Sample for number of users, non-users\n",
    "users = np.random.binomial(n, 0.005, 1) \n",
    "non_users = n - users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many of these users tested +ve ?\n",
    "u_pos = np.random.binomial(users, 0.99)\n",
    "# How many of these non-users tested +ve ?\n",
    "non_pos = np.random.binomial(non_users, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many of those +ve tests were for users?\n",
    "u_pos/(u_pos+non_pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discussion**: What you have been able to do here is to solve the following problem: you knew $P(+|user)=0.99$, but you were trying to figure out $P(user|+)$. Is the answer what you expected? If not, why not?\n",
    "\n",
    "**Key note:** This is related to the serious scientific challenge posed at the beginning here: if you know the underlying parameters/model, you can figure out the distribution and the result, but often we have only the experimental result and we're trying to figure out the most appropriate model and parameters.\n",
    "\n",
    "It is Bayes' Theorem that lets us move between these."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Bayes' Theorem\n",
    "\n",
    "$$P(B|A) = \\frac{P(A|B)P(B)}{P(A)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you may have guessed, it is Bayes' Theorem that will allow us to move back and forth between $P(data|model)$ and $P(model|data)$. As we have seen, $P(model|data)$ is usually what we're interested in as data scientists yet $P(data|model)$ is what we can easily compute, either by simulating our model or using analytic equations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**One of the coolest things:** Bayes Theorem can be proved with a few lines of mathematics. Your instructor will do this on the chalk/white-board now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayes Theorem solves the above drug testing problem\n",
    "\n",
    "Bayes Theorem can be used to analytically derive the solution to the 'drug testing' example above as follows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From Bayes Theorem, \n",
    "\n",
    "$$P(user|+) = \\frac{P(+|user)P(user)}{P(+)}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can expand the denominator here into \n",
    "\n",
    "$$P(+)  = P(+,user) + P(+,non-user) $$\n",
    "\n",
    "so that\n",
    "\n",
    "$$ P(+)=P(+|user)P(user) + P(+|non-user)P(non-user)$$\n",
    "\n",
    "and \n",
    "\n",
    "$$P(user|+) = \\frac{P(+|user)P(user)}{P(+|user)P(user) + P(+|non-user)P(non-user)}$$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating this explicitly yields\n",
    "\n",
    "$$P(user|+) = \\frac{0.99\\times 0.005}{0.99\\times 0.005 + 0.01\\times 0.995} = 0.332 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that if an individual tests positive, there is still only a 33.2% chance that they are a user! This is because the number of non-users is so high compared to the number of users."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coming up: from Bayes Theorem to Bayesian Inference!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bayesian-modelling-tutorial",
   "language": "python",
   "name": "bayesian-modelling-tutorial"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
