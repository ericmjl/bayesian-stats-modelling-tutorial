{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pymc3 as pm\n",
    "import seaborn as sns\n",
    "import arviz as az\n",
    "from utils import ECDF\n",
    "from data import load_kruschke\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian comparison of two (or more) groups\n",
    "\n",
    "Comparison of two groups is a ubiquitous inference task. You'll find it in many places:\n",
    "\n",
    "- Experimental biologists have a control group and some treatment.\n",
    "- Marketers call this A/B testing.\n",
    "- In clinical research, we'll have a case and control group, in which the case group receives an intervention. \n",
    "\n",
    "In this notebook, we will be introducing the use of PyMC3, a probabilistic programming language for Bayesian statistical modelling, and we will show how you can use PyMC3 to perform inference on this common statistical task.\n",
    "\n",
    "This notebook will be more guided than the latter ones, to help you get familiar with the syntax."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1: The Intervention-IQ Problem\n",
    "\n",
    "### Data Credits\n",
    "\n",
    "The data for this exercise was obtained from John Kruschke's paper, [Bayesian Estimation supersedes the T-test][best]. The data come from a fictional study of a drug and its effect on IQ, and have been slightly modified for pedagogical reasons.\n",
    "\n",
    "[best]: http://www.indiana.edu/~kruschke/BEST/BEST.pdf\n",
    "\n",
    "### Setup\n",
    "\n",
    "You are consulting for an academic research group, which would like to independently evaluate whether an intervention boosts IQ or not. To investigate this problem, the research group has set up a case-control study, comparing the IQ of students with and without the intervention. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Define Data Generating Process\n",
    "\n",
    "Without looking at the data, let us first think about the generative model for the data. \n",
    "\n",
    "Generative models, you might ask?\n",
    "\n",
    "A generative model is not necessarily a mechanistic model, in which every last detail is captured. Rather, a generative model lets us use probability distributions to express how the data were generated.\n",
    "\n",
    "One strategy for the data generating process is to go forward from first principles. This tends to be more mechanistic and principled, particularly when we are modelling a physical system or a known process.\n",
    "\n",
    "The other strategy is to go backwards from what the data might look like. This is useful when we do not have all of the necessary details, and is a flexible way to approximate how our data were generated. \n",
    "\n",
    "For this particular problem, we will take the latter strategy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Intervention IQ Data Generating Process\n",
    "\n",
    "The data generating process for this problem may be specified as such:\n",
    "\n",
    "1. We know that the IQ can be approximately modelled by normal distributions. \n",
    "    1. Because interventions in humans are generally expensive, we typically take few samples. Thus, instead of a normal distribution, which makes strong assumptions about having skinny tails (low probability mass in the extremes), we might want its more flexible cousin, the t-distribution. \n",
    "    1. This forms the **likelihood function** for the data.\n",
    "1. The t-distribution is parameterized by three parameters:\n",
    "    1. Mean\n",
    "    1. Variance (or standard deviation)\n",
    "    1. Degrees of Freedom (DoF)\n",
    "1. It is for these data parameters for which we require **priors**. \n",
    "    1. Mean: Assuming no good prior information, it is common to use a relatively wide normal distribution: $\\mu \\sim N(0, 100)$\n",
    "    1. Variance: Should be positive. Assuming no prior information, use a relatively flat positive distribution: $\\sigma \\sim HalfCauchy(100)$\n",
    "    1. Degrees of Freedom ($\\nu$): Should be positive and not equal to zero. We know some properties of DoF: when degrees of freedom is equal to 1, the t-distribution is equivalent to a Cauchy distribution, and as degrees of freedom go to infinity, the t-distribution becomes more and more like a Normal distribution.\n",
    "        1. This is a nuisance parameter - we need it for modelling with the t-distribution, but we don't really care about it .\n",
    "        1. [Questions have been asked][stats_exchange] regarding what are good priors. Check out [this link][stats_exchange] for more information.\n",
    "        1. Therefore, just as with the other parameters, we can assign a fairly flat degree of freedom parameter, and let the data speak for itself.\n",
    "        \n",
    "        \n",
    "[stats_exchange]: https://stats.stackexchange.com/questions/6492/whats-a-good-prior-distribution-for-degrees-of-freedom-in-a-t-distribution\n",
    "\n",
    "With this setup, we have *explicitly stated our assumptions* about what we believe about the data generating process, prior to having seen any data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In pictures, that big chunk of bullet points above can be visualized as follows:\n",
    "\n",
    "![](../images/kruschke_model.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Explore the Data\n",
    "\n",
    "Now that we have a first-pass generative model for the data, let's do some quick sanity checks against the data.\n",
    "\n",
    "Let's get started by loading the data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_kruschke()\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Plot the number of samples for drug and for treatment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More important than the number of samples per treatment is the distribution of IQ, which will give us a hint as to whether we can expect a difference in effect.\n",
    "\n",
    "**Exercise:** Plot the ECDF of the treatments vs. control. If you need to inspect the source code of ECDF, it is available below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ECDF??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code below.\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1)\n",
    "\n",
    "# Grab out just the placebo-treated and drug-treated participant IQs as individual iterables.\n",
    "placebo_data =       # your code here\n",
    "drug_data = \n",
    "\n",
    "# Use the ECDF function here.\n",
    "x_ctrl, y_ctrl = \n",
    "x_treat, y_treat = \n",
    "\n",
    "\n",
    "# Now we can plot the ECDF.\n",
    "ax.plot(x_ctrl, y_ctrl, label='placebo')\n",
    "ax.plot(x_treat, y_treat, label='drug')\n",
    "ax.set_xlabel('IQ')\n",
    "ax.set_ylabel('Cumulative Fraction')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discuss:** Does it look like the treatment had an effect on the IQ of the participants? What numbers from the chart above can help support your conclusions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Fit Model\n",
    "\n",
    "**Exercise:** We will specify the model below. Fill in the distributions as we go along in class. We are proceeding slowly here, simply to give you repetition practice with PyMC3's syntax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as kruschke_model:\n",
    "    \n",
    "    # Prior for drug-treated IQ mean.\n",
    "    mu_drug = \n",
    "    # Prior for placebo-treated IQ mean.\n",
    "    mu_placebo = \n",
    "    \n",
    "    # Prior for drug treated IQ standard deviation.\n",
    "    sigma_drug = \n",
    "    # Prior for placebo treated IQ standard deviation.\n",
    "    sigma_placebo = \n",
    "    \n",
    "    # Prior for nuisance parameter. Adding a small positive number \n",
    "    # guarantees that we never get nu == 0 by accident \n",
    "    # (e.g. through rounding error).\n",
    "    nu = \n",
    "    \n",
    "    # Likelihood function for the drug-treated participants' IQ.\n",
    "    drug_like = \n",
    "    \n",
    "    # Likelihood function for the placebo-treated participants' IQ.\n",
    "    placebo_like = \n",
    "    \n",
    "    # Calculate the effect size and its uncertainty.\n",
    "    diff_means = \n",
    "    pooled_sd = \n",
    "    effect_size = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few pointers to help you read the code.\n",
    "\n",
    "PyMC3 distributions are implemented using Distribution objects. Their object names match their distribution names. This is a very nice implementation detail of PyMC3! Additionally, [the docs][pymc3] show the parameters that are accepted; occasionally, the default parameterization might differ from what you have seen before, so referring to the docs is very important. \n",
    "\n",
    "[pymc3]: http://docs.pymc.io\n",
    "\n",
    "`pm.Deterministic` allows us to compute a deterministic transform on the random variables. Wrapping this in a Deterministic object allows us to hook the result of the transformation into the tools used later for visualizing posterior distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we hit the Inference Button!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with _________:\n",
    "    trace = ___________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize the posterior distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use `az.plot_posterior()`\n",
    "pm.__________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Evaluate Model\n",
    "\n",
    "We use posterior predictive checks (PPC) as one tool in our toolkit to evaluate and critique the model. The overarching goal of the PPC is to check that the data generating model generates simulated data that matches closely to the actual data. If this is the case, then we have a model that probably describes the data generating process well. If this is not the case, then we have evidence to go guide us towards re-doing the model.\n",
    "\n",
    "**Exercise:** To do a PPC, PyMC3 provides a `sample_ppc` function, which allows us to draw samples from the posterior distribution as a check. Run the following cell, filling in the appropriate `trace` and `model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use pm.sample_ppc()\n",
    "samples = ___________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Let's now plot the ECDF of the sampled data against the original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples['drug'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, [ax1, ax2] = plt.subplots(nrows=1, ncols=2, sharex=True)\n",
    "\n",
    "x, y = _____________  # Want ECDF of drug-treatment PPC samples\n",
    "ax1.plot(x, y, label='ppc')\n",
    "x, y = _____________  # Want ECDF of drug-treatment data\n",
    "ax1.plot(x, y, label='data')\n",
    "ax1.legend()\n",
    "ax1.set_title('drug treatment')\n",
    "ax1.set_xlabel('IQ')\n",
    "ax1.set_ylabel('Cumulative Fraction')\n",
    "\n",
    "x, y = _____________  # Want ECDF of placebo-treatment PPC samples\n",
    "ax2.plot(x, y, label='ppc')\n",
    "x, y = _____________  # Want ECDF of placebo-treatment data\n",
    "ax2.plot(x, y, label='data')\n",
    "ax2.legend()\n",
    "ax2.set_title('placebo')\n",
    "ax2.set_xlabel('IQ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like we have a model that, just by eyeballing the charts, models pretty well the distribution of the observed data.\n",
    "\n",
    "For pedagogical brevity, we did not dive into a case where the model was plausibly but nonetheless incorrectly specified. Under an incorrect model, we would expect the PPC and data distributions to be anywhere from moderately to wildly off. Having detected this from a visual comparison of the PPC samples and data, we would go back and try to see where we went wrong. We might also opt to quantify this difference using the tools provided in PyMC3. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Now, let us evaluate whether the drug actually did have an effect. Recall that we computed the difference in means, as well as an effect size, both with uncertainty. Using this information, plot the posterior distribution of the difference in means and effect sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use `az.plot_posterior`, but pass in different varnames\n",
    "_______________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questions:\n",
    "\n",
    "1. What is the 95% highest posterior density (HPD) interval for the difference of means?\n",
    "1. What is the 95% HPD interval for the effect size?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Compute the p-value of the t-test for this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "\n",
    "ttest_ind(df[placebo_filter]['iq'], df[drug_filter]['iq'], equal_var=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discuss**:\n",
    "1. Is there a significant difference between the drug-treated and placebo-treated participants of the intervention? (This question is intentionally vague on the definition of \"significant\", to encourage discussion of the difference between statistical and practical significance.)\n",
    "1. Would you recommend the intervention as a method to raise people's IQ? How much money would you be willing to pay for this intervention?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Reading/Watching\n",
    "\n",
    "- PyMC3's documentation contains an example of how to do [model selection][model_selection], which we did not touch on here. \n",
    "- John Kruschke's paper on [Bayesian Estimation][bayes_est] is what this notebook's example is based on. There is also a [YouTube video][bayes_yt] available.\n",
    "\n",
    "[model_selection]: https://docs.pymc.io/notebooks/GLM-model-selection.html\n",
    "[bayes_est]: http://www.indiana.edu/~kruschke/BEST/BEST.pdf\n",
    "[bayes_yt]: https://www.youtube.com/watch?v=fhw1j1Ru2i0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternative Syntax\n",
    "\n",
    "There is an alternative syntax that can be used, one that takes advantage of numpy-like fancy indexing. See it below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as kruschke_model_alt:\n",
    "    \n",
    "    # We have two mus, therefor we have a vector of distributions of shape (2,).\n",
    "    # Likewise for sds.\n",
    "    mus = pm.Normal('mu', mu=0, sd=100**2, shape=(2,))\n",
    "    sds = pm.HalfCauchy('sigma', beta=100, shape=(2,))\n",
    "    \n",
    "    # Prior for nuisance parameter. Adding a small positive number \n",
    "    # guarantees that we never get nu == 0 by accident \n",
    "    # (e.g. through rounding error).\n",
    "    nu = pm.Exponential('nu', lam=1/29) + 1\n",
    "    \n",
    "    # Likelihood function for the IQ values.\n",
    "    # Fancy indexing allows us \n",
    "    likelihood = pm.StudentT('likelihood', nu=nu, mu=mus[df['treatment_enc']], \n",
    "                             sd=sds[df['treatment_enc']], observed=df['iq'])\n",
    "    \n",
    "    # Calculate the effect size and its uncertainty.\n",
    "    diff_means = pm.Deterministic('diff_means', mus[0] - mus[1])\n",
    "    pooled_sd = pm.Deterministic('pooled_sd', \n",
    "                                 np.sqrt(np.power(sds[0], 2) + \n",
    "                                         np.power(sds[1], 2) / 2))\n",
    "    effect_size = pm.Deterministic('effect_size', \n",
    "                                   diff_means / pooled_sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with kruschke_model_alt:\n",
    "    trace_alt = pm.sample(2000, tuning=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traces = az.plot_trace(trace_alt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_posterior(trace_alt, var_names=['mu', 'effect_size'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Steps\n",
    "\n",
    "If you are feeling comfortable with PyMC3's syntax, in particular fancy indexing, and would like to move onto trying your hand at solving an inference problem without more guidance, then please proceed to Notebook 5.\n",
    "\n",
    "If you are feeling the need to get more practice with PyMC3's syntax, then proceed to Notebook 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bayesian-modelling-tutorial",
   "language": "python",
   "name": "bayesian-modelling-tutorial"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
