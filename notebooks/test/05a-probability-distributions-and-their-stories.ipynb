{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probability distributions and their stories (Part 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Chapter 3, we saw that we could match data-generating processes with binary outcomes to the story of the binomial distribution:\n",
    "\n",
    "> The Binomial distribution's story is as follows: the number $r$ of successes in $n$ Bernoulli trials with probability $p$ of success, is Binomially distributed. \n",
    "\n",
    "There are many other distributions with stories also! In this chapter, we'll introduce several key distributions and their stories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each distribution, we'll introduce\n",
    "\n",
    "* the story,\n",
    "* the parameters, and\n",
    "* how to simulate it (which will include plotting histograms and ECDFs of our simulated data).\n",
    "\n",
    "We'll then show real-world examples of each distribution, when possible, and demonstrate how to fit the simulated model the empirical data. We'll also occasionally use our simulation skills to give us more insight into the distributions we're introducing, such as to simulate the relationship between the Poisson and Binomial distributions, or to simulate an example of the Central Limit Theorem.\n",
    "\n",
    "We'll first introduce Poisson distributions and then Gaussian distributions. With the Binomial, Poisson, and Gaussian, you'll already be well-equipped to model a variety of real-world phenomena! We'll then introduce the beta distribution, which is inordinately useful when we need to assign probabilities on unknown probalities (such as when specifying priors).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Poisson processes and the Poisson distribution\n",
    "\n",
    "### The Poisson story\n",
    "\n",
    "In the book [Information Theory, Inference and Learning Algorithms](https://www.amazon.com/Information-Theory-Inference-Learning-Algorithms/dp/0521642981), David MacKay tells the tale of a town called Poissonville, in which the buses have an odd schedule. Standing at a bus stop in Poissonville, the amount of time you have to wait for a bus is totally independent of when the previous bus arrived. This means you could watch a bus drive off and another arrive almost instantaneously, or you could be waiting for hours.\n",
    "\n",
    "Arrival of buses in Poissonville is what we call a Poisson process. The timing of the next event is completely independent of when the previous event happened. Many real-life processes behave in this way. \n",
    "\n",
    "* natural births in a given hospital (there is a well-defined average number of natural births per year, and the timing of one birth is independent of the timing of the previous one);\n",
    "* Landings on a website;\n",
    "* Meteor strikes;\n",
    "* Molecular collisions in a gas;\n",
    "* Deaths fro mhorse kicks;\n",
    "* Aviation incidents.\n",
    "\n",
    "Any process that matches the buses in Poissonville **story** is a Poisson process and the number of arrivals of a Poisson process in a given amount of time is Poisson distributed.\n",
    "\n",
    "### The parameter(s)\n",
    "\n",
    "The Poisson distribution has one parameter, the average number of arrivals in a given length of time. So, to match the story, we could consider the number of hits on a website in an hour with an average of six hits per hour. This is Poisson distributed.\n",
    "\n",
    "### Simulating the Poisson distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-30T07:02:43.087314Z",
     "iopub.status.busy": "2022-04-30T07:02:43.086654Z",
     "iopub.status.idle": "2022-04-30T07:02:45.842569Z",
     "shell.execute_reply": "2022-04-30T07:02:45.842022Z"
    }
   },
   "outputs": [],
   "source": [
    "#| output: false\n",
    "#Import packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.optimize\n",
    "from generative_thinking.utils import ecdf\n",
    "%matplotlib inline\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-30T07:02:45.861205Z",
     "iopub.status.busy": "2022-04-30T07:02:45.861043Z",
     "iopub.status.idle": "2022-04-30T07:02:46.052705Z",
     "shell.execute_reply": "2022-04-30T07:02:46.052260Z"
    }
   },
   "outputs": [],
   "source": [
    "# Generate Poisson-distributed data\n",
    "rng = np.random.default_rng(42)\n",
    "samples  =  rng.poisson(6, size=10**6)\n",
    "\n",
    "# Plot histogram\n",
    "plt.hist(samples, bins=21);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If this distribution looks familiar, you've got a good eye. The Poisson distribution is related to both the Binomial distribution _and_ the Normal distribution!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In fact, the Poisson distribution is the limit of the Binomial distribution for low probability of success and large number of trials, that is, for rare events. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see this, think about the stories. Picture this: you're doing a Bernoulli trial once a  minute for an hour, each with a success probability of 0.05. We would do 60 trials, and the number of successes is Binomially distributed, and we would expect to get about 3 successes. This is just like the Poisson story of seeing 3 buses on average arrive in a given interval of time. Thus the Poisson distribution with arrival rate equal to $np$ approximates a Binomial distribution for $n$ Bernoulli trials with probability $p$ of success (with $n$ large and $p$ small). This is useful because the Poisson distribution can be simpler to work with as it has only one parameter instead of two for the Binomial distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The ECDF for the Poisson distribution\n",
    "\n",
    "We'll now plot the ECDF of the Poisson-distributed data that we generated above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-30T07:02:46.055113Z",
     "iopub.status.busy": "2022-04-30T07:02:46.055010Z",
     "iopub.status.idle": "2022-04-30T07:02:46.419848Z",
     "shell.execute_reply": "2022-04-30T07:02:46.419538Z"
    }
   },
   "outputs": [],
   "source": [
    "# Generate x- and y-data for the ECDF\n",
    "x_p, y_p = ecdf(samples)\n",
    "\n",
    "# Plot the ECDF\n",
    "plt.plot(x_p, y_p, marker='.', linestyle='none');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Field goal attempts per game\n",
    "\n",
    "Let's first remind ourselves of the story behind the Poisson distribution.\n",
    "> The number of arrivals of a Poisson processes in a given set time interval is Poisson distributed.\n",
    "\n",
    "To quote Justin Bois, who developed this example [here](https://github.com/justinbois/dataframed-plot-examples/blob/master/lebron_field_goals.ipynb),\n",
    "\n",
    "> We could model field goal attempts in a basketball game using a Poisson distribution. When a player takes a shot is a largely stochastic process, being influenced by the myriad ebbs and flows of a basketball game. Some players shoot more than others, though, so there is a well-defined rate of shooting. Let's consider LeBron James's field goal attempts for the 2017-2018 NBA season.\n",
    "\n",
    "First thing's first, the data ([from here](https://www.basketball-reference.com/players/j/jamesle01/gamelog/2018)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-30T07:02:46.421806Z",
     "iopub.status.busy": "2022-04-30T07:02:46.421695Z",
     "iopub.status.idle": "2022-04-30T07:02:46.425323Z",
     "shell.execute_reply": "2022-04-30T07:02:46.424963Z"
    }
   },
   "outputs": [],
   "source": [
    "fga = [19, 16, 15, 20, 20, 11, 15, 22, 34, 17, 20, 24, 14, 14, \n",
    "       24, 26, 14, 17, 20, 23, 16, 11, 22, 15, 18, 22, 23, 13, \n",
    "       18, 15, 23, 22, 23, 18, 17, 22, 17, 15, 23, 8, 16, 25, \n",
    "       18, 16, 17, 23, 17, 15, 20, 21, 10, 17, 22, 20, 20, 23, \n",
    "       17, 18, 16, 25, 25, 24, 19, 17, 25, 20, 20, 14, 25, 26, \n",
    "       29, 19, 16, 19, 18, 26, 24, 21, 14, 20, 29, 16, 9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To show that this LeBron's attempts are ~ Poisson distributed, you're now going to plot the ECDF and compare it with the the ECDF of the Poisson distribution that has the mean of the data (technically, this is the maximum likelihood estimate).\n",
    "\n",
    "#### LeBron's ECDF\n",
    "\n",
    "We first generate the x and y values for the ECDF of LeBron's field attempt goals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-30T07:02:46.427110Z",
     "iopub.status.busy": "2022-04-30T07:02:46.427004Z",
     "iopub.status.idle": "2022-04-30T07:02:46.507417Z",
     "shell.execute_reply": "2022-04-30T07:02:46.507021Z"
    }
   },
   "outputs": [],
   "source": [
    "# Generate x & y data for ECDF\n",
    "x_ecdf, y_ecdf = ecdf(np.array(fga))\n",
    "# Plot the ECDF\n",
    "plt.plot(x_ecdf, y_ecdf, marker='.', linestyle='none');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The Poisson model for LeBron's field goal attempts\n",
    "\n",
    "Now we'll draw samples out of a Poisson distribution to get the theoretical ECDF (that is, simulating the model), plot it with the ECDF of the data and see how they look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-30T07:02:46.510358Z",
     "iopub.status.busy": "2022-04-30T07:02:46.510174Z",
     "iopub.status.idle": "2022-04-30T07:02:47.295911Z",
     "shell.execute_reply": "2022-04-30T07:02:47.295519Z"
    }
   },
   "outputs": [],
   "source": [
    "# Number of times we simulate the model\n",
    "n_reps = 1000\n",
    "\n",
    "# Plot ECDF of data\n",
    "plt.plot(x_ecdf, y_ecdf, '.', color='black');\n",
    "\n",
    "# Plot ECDF of model\n",
    "for _ in range(n_reps):\n",
    "    samples = rng.poisson(np.mean(fga), size=len(fga))\n",
    "    x_theor, y_theor = ecdf(samples)\n",
    "    plt.plot(x_theor, y_theor, '.', alpha=0.01, color='lightgray');\n",
    "\n",
    "\n",
    "# Label your axes\n",
    "plt.xlabel('field goal attempts')\n",
    "plt.ylabel('ECDF');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see from the ECDF that LeBron's field goal attempts per game are approximately Poisson distributed. Note that we are not being super rigorous here and that this is intentional. The goal is not to state that the data is indeed Poisson distributed at the X% significance level, but to give a sense of how real-world data can be matched to probability distributions via their statistical stories. Also note that this is inherently a frequentist approach: we are approximating the Poisson distributions by looking at the long-run frequencies of outcomes, when we simulate. But this is fine, as we're merely using it as visual inspection tool, rather than to draw inferences, and thus Bernoulli's fallacy is irrelevant here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Death by horse kick\n",
    "\n",
    "To show off our new skills, let's look at one of the more infamous examples of a Poisson distribution! In 1898, Ladislaus Bortkiewicz, a Russian economist and statistician, published a book called _The Law of Small Numbers_. It was about Poisson distributions and in it Bortkiewicz showed the number of soldiers kicked to death by horses each year in the French cavalry corps is Poisson distributed. This dataset has stood the test of time and holds up well as an example of Poisson-distributed data. To see this, let's first import the data and check it out (data from [here](https://www.randomservices.org/random/data/HorseKicks.html)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-30T07:02:47.298324Z",
     "iopub.status.busy": "2022-04-30T07:02:47.298103Z",
     "iopub.status.idle": "2022-04-30T07:02:47.309266Z",
     "shell.execute_reply": "2022-04-30T07:02:47.308849Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../datasets/Prussion Horse-Kick Data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now get it into a form of total number of kicks each year:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-30T07:02:47.311993Z",
     "iopub.status.busy": "2022-04-30T07:02:47.311803Z",
     "iopub.status.idle": "2022-04-30T07:02:47.317721Z",
     "shell.execute_reply": "2022-04-30T07:02:47.317268Z"
    }
   },
   "outputs": [],
   "source": [
    "df['kicks'] = df.drop(['Year'], axis=1).sum(axis=1)\n",
    "kicks = df['kicks']\n",
    "kicks.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We plot the ECDF of the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-30T07:02:47.319925Z",
     "iopub.status.busy": "2022-04-30T07:02:47.319801Z",
     "iopub.status.idle": "2022-04-30T07:02:47.404056Z",
     "shell.execute_reply": "2022-04-30T07:02:47.403550Z"
    }
   },
   "outputs": [],
   "source": [
    "# Generate x & y data for ECDF\n",
    "x_ecdf, y_ecdf = ecdf(np.array(kicks))\n",
    "# Plot the ECDF\n",
    "plt.plot(x_ecdf, y_ecdf, marker='.', linestyle='none');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's simulate the Poisson model and see how our simulation looks, when plotted with the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-30T07:02:47.406356Z",
     "iopub.status.busy": "2022-04-30T07:02:47.406216Z",
     "iopub.status.idle": "2022-04-30T07:02:48.201685Z",
     "shell.execute_reply": "2022-04-30T07:02:48.201317Z"
    }
   },
   "outputs": [],
   "source": [
    "# Number of times we simulate the model\n",
    "n_reps = 1000\n",
    "\n",
    "# Plot ECDF of data\n",
    "plt.plot(x_ecdf, y_ecdf, '.', color='black');\n",
    "\n",
    "# Plot ECDF of model\n",
    "for _ in range(n_reps):\n",
    "    samples = rng.poisson(np.mean(kicks), size=len(kicks))\n",
    "    x_theor, y_theor = ecdf(samples)\n",
    "    plt.plot(x_theor, y_theor, '.', alpha=0.01, color='lightgray');\n",
    "\n",
    "\n",
    "# Label your axes\n",
    "plt.xlabel('Number of Deaths by Kick')\n",
    "plt.ylabel('ECDF');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks good! The ECDFs are evidence for our data being Poisson distributed and for the process of being kicked to death by a horse being a Poisson process.\n",
    "\n",
    "### Simulating relationships between distributions: the Poisson and the Binomial\n",
    "\n",
    "We gave an argument above, along with an example, as to the nature of the relationship between the Poisson and Binomial distributions, in particular that \"the Poisson distribution is the limit of the Binomial distribution for low probability of success and large number of trials, that is, for rare events.\" It is possible to prove this relationship mathematically however such a proof, although rigorous, does not give an intution behind the relationship. To provide this intution, along with the argument and example presented above, it helps to simulate the data-generating process.\n",
    "\n",
    "Recalling the example,\n",
    "\n",
    "> [Y]ou're doing a Bernoulli trial once a  minute for an hour, each with a success probability of 0.05. We would do 60 trials, and the number of successes is Binomially distributed, and we would expect to get about 3 successes. This is just like the Poisson story of seeing 3 buses on average arrive in a given interval of time,\n",
    "\n",
    "\n",
    "We simulate it by generating 1,000 instances of doing 60 trials, each with $p=0.05$, and plot the ECDF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-30T07:02:48.203909Z",
     "iopub.status.busy": "2022-04-30T07:02:48.203783Z",
     "iopub.status.idle": "2022-04-30T07:02:48.279573Z",
     "shell.execute_reply": "2022-04-30T07:02:48.279175Z"
    }
   },
   "outputs": [],
   "source": [
    "bts = rng.binomial(60, 0.05, 1000)\n",
    "# Generate x & y data for ECDF\n",
    "x_ecdf, y_ecdf = ecdf(bts)\n",
    "# Plot the ECDF\n",
    "plt.plot(x_ecdf, y_ecdf, marker='.', linestyle='none');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll draw samples out of a Poisson distribution to get the theoretical ECDF (that is, simulating the model), plot it with the ECDF of the data and see how they look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-30T07:02:48.281705Z",
     "iopub.status.busy": "2022-04-30T07:02:48.281552Z",
     "iopub.status.idle": "2022-04-30T07:02:49.044965Z",
     "shell.execute_reply": "2022-04-30T07:02:49.044645Z"
    }
   },
   "outputs": [],
   "source": [
    "# Number of times we simulate the model\n",
    "n_reps = 1000\n",
    "\n",
    "# Plot ECDF of data\n",
    "plt.plot(x_ecdf, y_ecdf, '.', color='black');\n",
    "\n",
    "# Plot ECDF of model\n",
    "for _ in range(n_reps):\n",
    "    samples = rng.poisson(np.mean(bts), size=len(fga))\n",
    "    x_theor, y_theor = ecdf(samples)\n",
    "    plt.plot(x_theor, y_theor, '.', alpha=0.01, color='lightgray');\n",
    "\n",
    "\n",
    "# Label your axes\n",
    "plt.xlabel('Bernoulli trials')\n",
    "plt.ylabel('ECDF');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see from the ECDF that the results of the Bernoulli trials are approximately Poisson distributed. Now that we're familiar with both the Binomial and Poisson distributions, let's move on to the Gaussian!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Gaussian distribution\n",
    "\n",
    "### The Gaussian story\n",
    "\n",
    "The normal distribution, also known as the Gaussian or Bell Curve, appears everywhere, and we will use these terms interchangeably. There are many reasons for it being so widespread. One is the following:\n",
    "\n",
    "> When doing repeated measurements, we expect them to be normally distributed, owing to the many subprocesses that contribute to a measurement. This is because (a formulation of the Central Limit Theorem) **any quantity that emerges as the sum of a large number of subprocesses tends to be Normally distributed** provided none of the subprocesses is very broadly distributed.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### The parameters\n",
    "\n",
    "The normal distribution has two parameters, mean $\\mu$ and variance $\\sigma^2$. The mean, as you may expect, is the expected value (or average) of the distribution, while the variance captures the spread of the distribution.\n",
    "\n",
    "One useful way to consider them is $\\mu$ as a _location_ parameter and $\\sigma$ as a _shape_ parameter. What we really mean by this is that changing $\\mu$ will essentially translate the distribution along the x-axis, while changing $\\sigma^2$ will make the distribution wider or more narrow.\n",
    "\n",
    "### Simulating the Gaussian\n",
    "\n",
    "\n",
    "Let's now simulate a Gaussian distribution and plot the resulting histogram:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-30T07:02:49.047301Z",
     "iopub.status.busy": "2022-04-30T07:02:49.047164Z",
     "iopub.status.idle": "2022-04-30T07:02:49.206481Z",
     "shell.execute_reply": "2022-04-30T07:02:49.206105Z"
    }
   },
   "outputs": [],
   "source": [
    "samples = rng.normal(0, 1, size=10000)\n",
    "plt.hist(samples);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The ECDF of the Gaussian\n",
    "\n",
    "Let's also plot the ECDF of the Gaussian data we just simulated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-30T07:02:49.208504Z",
     "iopub.status.busy": "2022-04-30T07:02:49.208392Z",
     "iopub.status.idle": "2022-04-30T07:02:49.296016Z",
     "shell.execute_reply": "2022-04-30T07:02:49.295625Z"
    }
   },
   "outputs": [],
   "source": [
    "x, y = ecdf(samples)\n",
    "\n",
    "_ = plt.plot(x, y, marker='.', linestyle='none')\n",
    "\n",
    "_ = plt.ylabel('CDF')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An example of a Gaussian distribution: the speed of light\n",
    "\n",
    "Now it's time to see if this holds for the measurements of the speed of light in the famous Michelson–Morley experiment.\n",
    "\n",
    "Below, we'll plot the histogram with a Gaussian curve fitted to it. Even if that looks good, though, that could be due to binning bias. So then we'll plot the ECDF of the data and the CDF of the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-30T07:02:49.298213Z",
     "iopub.status.busy": "2022-04-30T07:02:49.298071Z",
     "iopub.status.idle": "2022-04-30T07:02:49.391068Z",
     "shell.execute_reply": "2022-04-30T07:02:49.390640Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load data, plot histogram \n",
    "import scipy.stats as st\n",
    "df = pd.read_csv('../../datasets/michelson_speed_of_light.csv')\n",
    "df = df.rename(columns={'velocity of light in air (km/s)': 'c'})\n",
    "c = df.c.values\n",
    "x_s = np.linspace(299.6, 300.1, 400) * 1000\n",
    "plt.plot(x_s, st.norm.pdf(x_s, c.mean(), c.std(ddof=1)))\n",
    "plt.hist(c, bins=9, density=True)\n",
    "plt.xlabel('speed of light (km/s)')\n",
    "plt.ylabel('PDF');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Speed of light data and Gaussian model ECDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-30T07:02:49.393179Z",
     "iopub.status.busy": "2022-04-30T07:02:49.393058Z",
     "iopub.status.idle": "2022-04-30T07:02:49.478306Z",
     "shell.execute_reply": "2022-04-30T07:02:49.477927Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get speed of light measurement + mean & standard deviation\n",
    "michelson_speed_of_light = df.c.values\n",
    "mean = np.mean(michelson_speed_of_light)\n",
    "std = np.std(michelson_speed_of_light, ddof=1)\n",
    "\n",
    "# Generate normal samples w/ mean,  std of data\n",
    "samples = np.random.normal(mean, std, size=10000)\n",
    "\n",
    "# Generate data ECDF & model CDF\n",
    "x, y = ecdf(michelson_speed_of_light)\n",
    "x_theor, y_theor = ecdf(samples)\n",
    "\n",
    "# Plot data & model (E)CDFs\n",
    "_ = plt.plot(x_theor, y_theor)\n",
    "_ = plt.plot(x, y, marker='.', linestyle='none')\n",
    "_ = plt.xlabel('speed of light (km/s)')\n",
    "_ = plt.ylabel('CDF')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data looks pretty Gaussian to us! Some of you may ask but is the data really normal? I urge you to check out Allen Downey's post [_Are your data normal? Hint: no._ ](http://allendowney.blogspot.com/2013/08/are-my-data-normal.html)\n",
    "\n",
    "### The Central limit theorem\n",
    "\n",
    "Recall that, in Chapter 2, we used the bootstrap to estimate our uncertainty around the mean of the Fortis Finch beak length population:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-30T07:02:49.480732Z",
     "iopub.status.busy": "2022-04-30T07:02:49.480601Z",
     "iopub.status.idle": "2022-04-30T07:02:49.585742Z",
     "shell.execute_reply": "2022-04-30T07:02:49.585330Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import and view head of data\n",
    "df_12 = pd.read_csv('../../datasets/finch_beaks_2012.csv')\n",
    "df_fortis = df_12.loc[df_12['species'] == 'fortis']\n",
    "blf = df_fortis['blength']\n",
    "\n",
    "n = 10**3\n",
    "blf_means = np.zeros(n)\n",
    "\n",
    "for i in range(n):\n",
    "    samples = rng.choice(blf, len(blf))\n",
    "    mean = np.mean(samples)\n",
    "    blf_means[i] = mean\n",
    "    \n",
    "plt.hist(blf_means);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We noted that the distribution looks approximately normal so let's now plot the relevant ECDFs to confirm this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-30T07:02:49.587922Z",
     "iopub.status.busy": "2022-04-30T07:02:49.587768Z",
     "iopub.status.idle": "2022-04-30T07:02:49.667034Z",
     "shell.execute_reply": "2022-04-30T07:02:49.666662Z"
    }
   },
   "outputs": [],
   "source": [
    "mean = np.mean(blf_means)\n",
    "std = np.std(blf_means, ddof=1)\n",
    "\n",
    "# Generate normal samples w/ mean,  std of data\n",
    "samples = rng.normal(mean, std, size=1000)\n",
    "\n",
    "# Generate data ECDF & model CDF\n",
    "x_f, y_f = ecdf(blf_means)\n",
    "x_theor, y_theor = ecdf(samples)\n",
    "\n",
    "# Plot data & model (E)CDFs\n",
    "_ = plt.plot(x_theor, y_theor)\n",
    "_ = plt.plot(x_f, y_f)\n",
    "_ = plt.xlabel('blf means')\n",
    "_ = plt.ylabel('CDF')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That looks pretty good! Knowing the story of the normal distribution, why would this distribution be normally distributed? It comes down to the Central limit theorem! Recall that the CLT states that:\n",
    "\n",
    "> **any quantity that emerges as the sum of a large number of subprocesses tends to be Normally distributed** provided none of the subprocesses is very broadly distributed.\n",
    "\n",
    "And the mean is proportional to the sum of a large number of subprocesses, each of which is an individual measurement of a beak length. Now we've added the Gaussian distribution to our toolkit, let's wrap up this chapter by diving into the beta distribution, which will help us quantify uncertainty around unknown probabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beta distribution\n",
    "\n",
    "### The beta story\n",
    "\n",
    "We'll start by telling you the story of the beta distribution, for completeness' sake, but then we'll delve into other ways to get intution for the beta distribution:\n",
    "\n",
    "> Say you wait for two multistep processes to happen. The individual steps of each process happen at the same rate, but the first multistep process requires α steps and the second requires β steps. The fraction of the total waiting time take by the first process is beta distributed.\n",
    "\n",
    "\n",
    "This story doesn't really tell us some of the most salient aspects of the beta distribution. The most important aspect is that, using the beta distribution, we can assign probabilities on unknown probalities, such as what is the probability that $P(heads) = 0.5$ for a biased coin. The beta distribution is also defined only on $0≤x≤1$, and x can be thought of as the probability of a Bernoulli trial, for example.\n",
    "\n",
    "Consider the average CTR of two websites, **A** that was launched several minutes ago and **B** that has been live for some time. What we'd really like to do is to predict the CTR of both A and B but the thing is we have a lot more data on B and so can be more certain of the CTR we have calculated. Let's say that 10 people so far have landed on website A and nobody has clicked through. Would we assume that the CTR is likely zero, then? No, not at all! Why not?\n",
    "\n",
    "Because we're going in with prior information, namely that a CTR under 10% is quite common and that a CTR of 0% is very unlikely. And it is the beta distribution that allows us to encode this prior information.\n",
    "\n",
    "### The beta parameters\n",
    "\n",
    "$\\alpha$ and $\\beta$, which are both _shape_ parameters. These uniquely define the beta distribution, in accordance with the story of the distribution told above. As we'll see below, when $\\alpha=\\beta=1$, the beta distribution is equivalent to the uniform distribution and, due the to 2 degrees of freedom, the beta distribution is versatile and widely applicable.\n",
    "\n",
    "\n",
    "### Simulating the beta distribution\n",
    "\n",
    "\n",
    "To simulate the beta distribution, we'll need to pick some parameters so let's do it a couple of times.\n",
    "\n",
    "\n",
    "Let's first simulate $\\beta(1, 1)$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-30T07:02:49.669320Z",
     "iopub.status.busy": "2022-04-30T07:02:49.669173Z",
     "iopub.status.idle": "2022-04-30T07:02:49.754985Z",
     "shell.execute_reply": "2022-04-30T07:02:49.754566Z"
    }
   },
   "outputs": [],
   "source": [
    "samples_1 = rng.beta(1, 1, 10**3)\n",
    "plt.hist(samples_1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's no coincidence that it looks like the uniform distribution... because it is! This encodes no former knowledge about the CTR, except that it lays between 0 and 1 and all possible values therein are equally likely. One the really cool aspects of the beta distribution is that, as we begin to see results from our experiments, we can update the beta distribution to include these results in an intuitive manner. In particular, if we see $a_0$ Os and $a_1$ 1s, we can update our distribution to $\\beta(1+a_1, 1+a_0)$ to encode this additional knowledge. Thus, were we to see 10 people not click through and  2 click-throughs, we would get $\\beta(3, 11)$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-30T07:02:49.757326Z",
     "iopub.status.busy": "2022-04-30T07:02:49.757172Z",
     "iopub.status.idle": "2022-04-30T07:02:49.843780Z",
     "shell.execute_reply": "2022-04-30T07:02:49.843300Z"
    }
   },
   "outputs": [],
   "source": [
    "samples_2 = rng.beta(3, 11, 10**3)\n",
    "plt.hist(samples_2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The ECDF of the beta distribution\n",
    "\n",
    "Let's now plot the ECDFs of these two distributions to get a feel for them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-30T07:02:49.846141Z",
     "iopub.status.busy": "2022-04-30T07:02:49.846001Z",
     "iopub.status.idle": "2022-04-30T07:02:49.924703Z",
     "shell.execute_reply": "2022-04-30T07:02:49.924334Z"
    }
   },
   "outputs": [],
   "source": [
    "x_1, y_1 = ecdf(samples_1)\n",
    "x_2, y_2 = ecdf(samples_2)\n",
    "\n",
    "plt.plot(x_1, y_1);\n",
    "plt.plot(x_2, y_2);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: baseball batting averages\n",
    "\n",
    "This is an example from sabermetrics (the mathematical and statistical analysis of baseball records). We'll be looking at average batting rate, which is analogous to the average CTR story above via matching both stories to the binomial distribution! This example is inspired by [several](http://varianceexplained.org/statistics/beta_distribution_and_baseball/) [blog posts](http://varianceexplained.org/r/empirical_bayes_baseball/) by David Robinson.\n",
    "\n",
    "Let's say we have a batter $A$ with 3 out of 10 hits and a batter $B$ with 250 out of $1000$ hits. $A$'s batting average is 0.3 and $B$'s is 0.25, but we have much less data to go on with $A$!\n",
    "\n",
    "But we also have a lot more data! In the end, we can use a technique known as _Empirical Bayes_ to get better estimates for the relevant batting averages, which involves two steps:\n",
    "\n",
    "1. Estimating a beta distribution for all the relevant data\n",
    "2. Use that distribution to retrieve estimates for each individual (such as $A$ and $B$).\n",
    "\n",
    "Here, we'll do Step 1 and we'll return to Step 2 after introducing Bayes' Theorem and Bayesian inference. The attentive reader may notice that we're referring to prior and posterior distributions in Steps 1 and 2 without yet using that language.\n",
    "\n",
    "So let's now import our data, clean it up a bit, and model it as a beta distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-30T07:02:49.926847Z",
     "iopub.status.busy": "2022-04-30T07:02:49.926690Z",
     "iopub.status.idle": "2022-04-30T07:02:50.167248Z",
     "shell.execute_reply": "2022-04-30T07:02:50.166937Z"
    }
   },
   "outputs": [],
   "source": [
    "df_batting = pd.read_csv('../../datasets/Batting.csv')\n",
    "df_p = pd.read_csv('../../datasets/Pitching.csv')\n",
    "df_batting.head()\n",
    "\n",
    "dfg = df_batting[['playerID','AB','H']].groupby(['playerID']).sum()\n",
    "dfg['Av'] = dfg['H']/dfg['AB']\n",
    "dfg.reset_index(inplace=True)\n",
    "dfg.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's clean up our data a bit by dropping pitchers, include only those with > 500 at bats, and dropping NaNs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-30T07:02:50.169545Z",
     "iopub.status.busy": "2022-04-30T07:02:50.169393Z",
     "iopub.status.idle": "2022-04-30T07:02:50.304610Z",
     "shell.execute_reply": "2022-04-30T07:02:50.304188Z"
    }
   },
   "outputs": [],
   "source": [
    "dfg = dfg[~dfg.playerID.isin(df_p.playerID.unique())]\n",
    "\n",
    "#df = dfg[dfg['Av'] > 0.18]\n",
    "dfg = dfg[dfg['AB'] > 500]\n",
    "dfg.dropna(inplace=True)\n",
    "plt.hist(dfg['Av'],bins=50);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now fit a beta distribution to the data, simulate from the beta, and plot the resulting histogram:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-30T07:02:50.306955Z",
     "iopub.status.busy": "2022-04-30T07:02:50.306668Z",
     "iopub.status.idle": "2022-04-30T07:02:50.434934Z",
     "shell.execute_reply": "2022-04-30T07:02:50.434607Z"
    }
   },
   "outputs": [],
   "source": [
    "data = dfg['Av']\n",
    "m = np.mean(data)\n",
    "v = np.var(data)\n",
    "print(m, v)\n",
    "a = m**2*((1-m)/v - 1/m)\n",
    "b = a*(1/m - 1)\n",
    "print(a, b)\n",
    "samples = rng.beta(a, b, 10**3)\n",
    "plt.hist(samples, bins=50);\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then compute and plot and ECDFs for the data and the simulated model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-30T07:02:50.437043Z",
     "iopub.status.busy": "2022-04-30T07:02:50.436927Z",
     "iopub.status.idle": "2022-04-30T07:02:50.524893Z",
     "shell.execute_reply": "2022-04-30T07:02:50.524386Z"
    }
   },
   "outputs": [],
   "source": [
    "# Compute ECDFs for sample & model\n",
    "x, y = ecdf(np.array(data))\n",
    "x_theor, y_theor = ecdf(np.array(samples))\n",
    "# Plot sample & model ECDFs\n",
    "plt.plot(x_theor, y_theor);\n",
    "plt.plot(x, y, marker='.', linestyle='none', alpha=0.03);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that out data is approximately beta distributed, where $\\alpha\\approx 80$ and $\\beta\\approx 229.$\n",
    "After we introduce Bayes' Theorem and Bayesian inference, we'll see how this can be updated to retrieve estimates for individual batters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrapping up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this chapter, we have introduced 4 key distributions that will provide a firm foundation for any future statistical modeling. In particular, we have focused on matching distributions to their stories, in order to give intuition for how we think about these distributions and how they correspond to the way we encode the data-generating processes in our modeling choices.\n",
    "\n",
    "We've seen how many of the datasets are related and used our simulation skills to demonstrate these relationships. We've also looked at a variety of real-world datasets, considered what data-generating processes could have resulted in them, fit the relevant models to the data, and used the ECDF to visualize the data and the model together, in order to get a visual sense of the goodness of fit.\n",
    "\n",
    "Now we have a stronger sense of our foundational family of distributions, it's time to move onto other distributions that will be useful to any statistical modeler."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
