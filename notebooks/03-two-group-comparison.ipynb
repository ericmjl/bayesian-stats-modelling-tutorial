{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian comparison of two (or more) groups\n",
    "\n",
    "Comparison of two groups is a ubiquitous inference task. You'll find it in many places:\n",
    "\n",
    "- Experimental biologists have a control group and some treatment.\n",
    "- Marketers call this A/B testing.\n",
    "- In clinical research, we'll have a case and control group, in which the case group receives an intervention. \n",
    "\n",
    "In this notebook, we will be introducing the use of PyMC3, a probabilistic programming language for Bayesian statistical modelling, and we will show how you can use PyMC3 to perform inference on this common statistical task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1: The Intervention-IQ Problem\n",
    "\n",
    "### Data Credits\n",
    "\n",
    "The data for this exercise was obtained from John Kruschke's paper, [Bayesian Estimation supersedes the T-test][best]. The data come from a fictional study of a drug and its effect on IQ, and have been slightly modified for pedagogical reasons.\n",
    "\n",
    "[best]: http://www.indiana.edu/~kruschke/BEST/BEST.pdf\n",
    "\n",
    "### Setup\n",
    "\n",
    "You are consulting for an academic research group, which would like to independently evaluate whether an intervention boosts IQ or not. To investigate this problem, the research group has set up a case-control study, comparing the IQ of students with and without the intervention. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Define Data Generating Process\n",
    "\n",
    "Without looking at the data, let us first think about the generative model for the data. \n",
    "\n",
    "Generative models, you might ask?\n",
    "\n",
    "A generative model is not necessarily a mechanistic model, in which every last detail is captured. Rather, a generative model lets us use probability distributions to express how the data were generated.\n",
    "\n",
    "One strategy for the data generating process is to go forward from first principles. This tends to be more mechanistic and principled, particularly when we are modelling a physical system or a known process.\n",
    "\n",
    "The other strategy is to go backwards from what the data might look like. This is useful when we do not have all of the necessary details, and is a flexible way to approximate how our data were generated. \n",
    "\n",
    "For this particular problem, we will take the latter strategy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Intervention IQ Data Generating Process\n",
    "\n",
    "The data generating process for this problem may be specified as such:\n",
    "\n",
    "1. We know that the IQ can be approximately modelled by normal distributions. \n",
    "    1. Because interventions in humans are generally expensive, we typically take few samples. Thus, instead of a normal distribution, which makes strong assumptions about having skinny tails (low probability mass in the extremes), we might want its more flexible cousin, the t-distribution. \n",
    "    1. This forms the **likelihood function** for the data.\n",
    "1. The t-distribution is parameterized by three parameters:\n",
    "    1. Mean\n",
    "    1. Variance (or standard deviation)\n",
    "    1. Degrees of Freedom (DoF)\n",
    "1. It is for these data parameters for which we require **priors**. \n",
    "    1. Mean: Assuming no good prior information, it is common to use a relatively wide normal distribution: $\\mu \\sim N(0, 100)$\n",
    "    1. Variance: Should be positive. Assuming no prior information, use a relatively flat positive distribution: $\\sigma \\sim HalfCauchy(100)$\n",
    "    1. Degrees of Freedom ($\\nu$): Should be positive and not equal to zero. We know some properties of DoF: when degrees of freedom is equal to 1, the t-distribution is equivalent to a Cauchy distribution, and as degrees of freedom go to infinity, the t-distribution becomes more and more like a Normal distribution.\n",
    "        1. This is a nuisance parameter - we need it for modelling with the t-distribution, but we don't really care about it .\n",
    "        1. [Questions have been asked][stats_exchange] regarding what are good priors. Check out [this link][stats_exchange] for more information.\n",
    "        1. Therefore, just as with the other parameters, we can assign a fairly flat degree of freedom parameter, and let the data speak for itself.\n",
    "        \n",
    "        \n",
    "[stats_exchange]: https://stats.stackexchange.com/questions/6492/whats-a-good-prior-distribution-for-degrees-of-freedom-in-a-t-distribution\n",
    "\n",
    "With this setup, we have *explicitly stated our assumptions* about what we believe about the data generating process, prior to having seen any data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In pictures, that big chunk of bullet points above can be visualized as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML, Image\n",
    "\n",
    "Image(filename='../images/kruschke_model.jpg', width=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Explore the Data\n",
    "\n",
    "Now that we have a first-pass generative model for the data, let's do some quick sanity checks against the data.\n",
    "\n",
    "#### Exercise 1\n",
    "\n",
    "Load the dataset into a pandas DataFrame. It is available at the path `../data/iq.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../data/iq.csv', index_col=0)  # comment out the path to the file for students.\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 2\n",
    "\n",
    "Plot the number of samples for drug and for treatment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('treatment').size().plot(kind='bar')  # blank out \"treatment\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More important than the number of samples per treatment is the distribution of IQ, which will give us a hint as to whether we can expect a difference in effect.\n",
    "\n",
    "#### Exercise 3\n",
    "\n",
    "Plot the ECDF of the treatments vs. control."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ECDF(data):\n",
    "    x = np.sort(data)\n",
    "    y = np.cumsum(x) / np.sum(x)\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "placebo_filter = df['treatment'] == 'placebo'\n",
    "drug_filter = df['treatment'] == 'drug'\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1)\n",
    "x_ctrl, y_ctrl = ECDF(df[placebo_filter]['iq'])\n",
    "x_treat, y_treat = ECDF(df[drug_filter]['iq'])\n",
    "\n",
    "ax.plot(x_ctrl, y_ctrl, label='placebo')\n",
    "ax.plot(x_treat, y_treat, label='drug')\n",
    "ax.set_xlabel('IQ')\n",
    "ax.set_ylabel('Cumulative Fraction')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discuss\n",
    "\n",
    "Does it look like the treatment had an effect on the IQ of the participants? What numbers from the chart above can help support your conclusions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Fit Model\n",
    "\n",
    "#### Exercise\n",
    "\n",
    "The model for this dataset can be specified as such. Follow along on the annotated comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as kruschke_model:\n",
    "    \n",
    "    # Prior for drug-treated IQ mean.\n",
    "    mu_drug = pm.Normal('mu_drug', mu=0, sd=100**2)\n",
    "    # Prior for placebo-treated IQ mean.\n",
    "    mu_placebo = pm.Normal('mu_placebo', mu=0, sd=100**2)\n",
    "    \n",
    "    # Prior for drug treated IQ standard deviation.\n",
    "    sigma_drug = pm.HalfCauchy('sigma_drug', beta=100)\n",
    "    # Prior for placebo treated IQ standard deviation.\n",
    "    sigma_placebo = pm.HalfCauchy('sigma_placebo', beta=100)\n",
    "    \n",
    "    # Prior for nuisance parameter. Adding a small positive number \n",
    "    # guarantees that we never get nu == 0 by accident \n",
    "    # (e.g. through rounding error).\n",
    "    nu = pm.Exponential('nu', lam=1/29) + 1\n",
    "    \n",
    "    # Likelihood function for the drug-treated participants' IQ.\n",
    "    drug_like = pm.StudentT('drug', nu=nu, mu=mu_drug, \n",
    "                            sd=sigma_drug, observed=df[drug_filter]['iq'])\n",
    "    \n",
    "    # Likelihood function for the placebo-treated participants' IQ.\n",
    "    placebo_like = pm.StudentT('placebo', nu=nu, mu=mu_placebo, \n",
    "                               sd=sigma_placebo, observed=df[placebo_filter]['iq'])\n",
    "    \n",
    "    # Calculate the effect size and its uncertainty.\n",
    "    diff_means = pm.Deterministic('diff_means', mu_drug - mu_placebo)\n",
    "    pooled_sd = pm.Deterministic('pooled_sd', \n",
    "                                 np.sqrt(np.power(sigma_drug, 2) + \n",
    "                                         np.power(sigma_placebo, 2) / 2))\n",
    "    effect_size = pm.Deterministic('effect_size', \n",
    "                                   diff_means / pooled_sd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we hit the Inference Button!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with kruschke_model:\n",
    "    trace = pm.sample(2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize the posterior distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.plot_posterior(trace, varnames=['mu_drug', 'mu_placebo'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Evaluate Model\n",
    "\n",
    "We use posterior predictive checks (PPC) as one tool in our toolkit to evaluate and critique the model. The overarching goal of the PPC is to check that the data generating model generates simulated data that matches closely to the actual data. If this is the case, then we have a model that probably describes the data generating process well. If this is not the case, then we have evidence to go guide us towards re-doing the model.\n",
    "\n",
    "#### Exercise\n",
    "\n",
    "To do a PPC, PyMC3 provides a `sample_ppc` function, which allows us to draw samples from the posterior distribution as a check. Run the following cell, filling in the appropriate `trace` and `model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = pm.sample_ppc(trace=trace, samples=500, model=kruschke_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise\n",
    "\n",
    "Let's now plot the ECDF of the sampled data against the original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "fig, [ax1, ax2] = plt.subplots(nrows=1, ncols=2, sharex=True)\n",
    "\n",
    "x, y = ECDF(samples['drug'])  # Want ECDF of drug-treatment PPC samples\n",
    "ax1.plot(x, y, label='ppc')\n",
    "x, y = ECDF(df[drug_filter]['iq'])  # Want ECDF of drug-treatment data\n",
    "ax1.plot(x, y, label='data')\n",
    "ax1.legend()\n",
    "ax1.set_title('drug treatment')\n",
    "ax1.set_xlabel('IQ')\n",
    "ax1.set_ylabel('Cumulative Fraction')\n",
    "\n",
    "x, y = ECDF(samples['placebo'])  # Want ECDF of placebo-treatment PPC samples\n",
    "ax2.plot(x, y, label='ppc')\n",
    "x, y = ECDF(df[placebo_filter]['iq'])  # Want ECDF of placebo-treatment data\n",
    "ax2.plot(x, y, label='data')\n",
    "ax2.legend()\n",
    "ax2.set_title('placebo')\n",
    "ax2.set_xlabel('IQ')\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like we have a model that, just by eyeballing the data, models pretty well the distribution of the observed data.\n",
    "\n",
    "For pedagogical brevity, we did not dive into a case where the model was plausibly but nonetheless incorrectly specified. Under an incorrect model, we would expect the PPC and data distributions to be anywhere from moderately to wildly off. Having detected this from a visual comparison of the PPC samples and data, we would go back and try to see where we went wrong.\n",
    "\n",
    "#### Exercise\n",
    "\n",
    "Now, let us evaluate whether the drug actually did have an effect. Recall that we computed the difference in means, as well as an effect size, both with uncertainty. Using this information, plot the posterior distribution of the difference in means and effect sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.plot_posterior(trace=trace, varnames=['diff_means', 'effect_size'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questions:\n",
    "\n",
    "1. What is the 95% highest posterior density (HPD) interval for the difference of means?\n",
    "1. What is the 95% HPD interval for the effect size?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise\n",
    "\n",
    "Compute the p-value of the t-test for this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "\n",
    "ttest_ind(df[placebo_filter]['iq'], df[drug_filter]['iq'], equal_var=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discuss\n",
    "\n",
    "1. Is there a significant difference between the drug-treated and placebo-treated participants of the intervention? (This question is intentionally vague on the definition of \"significant\", to encourage discussion of the difference between statistical and practical significance.)\n",
    "1. Would you recommend the intervention as a method to raise people's IQ? How much money would you be willing to pay for this intervention?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further Reading/Watching\n",
    "\n",
    "- PyMC3's documentation contains an example of how to do [model selection][model_selection], which we did not touch on here. \n",
    "- John Kruschke's paper on [Bayesian Estimation][bayes_est] is what this notebook's example is based on. There is also a [YouTube video][bayes_yt] available.\n",
    "\n",
    "[model_selection]: https://docs.pymc.io/notebooks/GLM-model-selection.html\n",
    "[bayes_est]: http://www.indiana.edu/~kruschke/BEST/BEST.pdf\n",
    "[bayes_yt]: https://www.youtube.com/watch?v=fhw1j1Ru2i0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Steps\n",
    "\n",
    "If you are feeling comfortable with PyMC3's syntax, and would like to move onto trying your hand at solving an inference problem without more guidance, then please proceed to Notebook 5.\n",
    "\n",
    "If you are feeling the need to get more practice with PyMC3's syntax, then proceed to Notebook 4."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bayesian-modelling-tutorial",
   "language": "python",
   "name": "bayesian-modelling-tutorial"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
